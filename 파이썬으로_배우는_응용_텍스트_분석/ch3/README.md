# 말뭉치의 전처리와 가공
## 문서 쪼개보기
사용자 지정 말뭉치 리더는 NLTK의 CorpusReader 객체를 상속하므로 표준 전처리 API도 구현하여 다음과 같은 메서드도 제공한다.
- `raw()`
  - 전처리 없이 원시 텍스트에 대한 액세스를 제공한다.
- `sents()`
  - 본문에 있는 개별 문장의 생성자다.
- `words()`
  - 텍스트를 개별 단어로 토큰화한다.  

우리의 텍스트에 머신러닝 기술을 사용해 모델을 적합화하려면 이러한 방법을 특징추출 과정의 일부로 포함시켜야 한다.  

## 핵심 내용 식별 및 추출
HTML 콘텐츠는 구조화된 상태에서 수많은 방식으로, 그리고 때로는 엉뚱한 방식으로 제작되고 렌더링될 수 있다. 이러한 예측 불가능성으로 인해 체계적인 방식으로 프로그램을 사용해서 원시 HTML 텍스트에서 데이터를 추출하기가 무척 어렵다.  

Readability-lxml 라이브러리는 웹에서 수집된 문서의 높은 변동성을 다루기에 정말 좋은 자원이다. Readability-lxml은 Arc90에 의한 자바스크립트 가독성 실험용 파이썬 래퍼다. 사파리나 크롬 같은 브라우저와 마찬가지로 읽기 모드를 제공하므로 Readability-lxml은 페이지의 내용에서 잡다한 것들을 제거해 텍스트만 남긴다.  

HTML 문서가 주어진 경우 Readability는 일련의 정규 표현식을 사용하여 탐색 모음, 광고, 페이지 스크립트 태그 및 CSS를 제거한 다음. 새로운 **문서 객체 모델(DOM)**트리를 작성하고, 원래 트리에서 텍스트를 추출하고, 새로 재구성된 트리 내에서 텍스트를 재구성한다. 다음 번에 나오는 HTMLCorpusReader를 확장한 예제에서 우리는 Unparseable 및 Document라는 두 가지 가독성 모듈을 가져와 전처리 작업흐름의 첫 번째 단계에서 원시 HTML 텍스트를 추출하고 정리한다.  

html 메서드는 각 파일을 반복하고 readability.Document 클래스의 summary 메서드를 사용해 스크립트가 아닌 모든 텍스트 콘텐트와 sty-listic 태그를 제거한다. 또한, 가장 자주 잘못 사용되는 태그(e.g. `<div>`와 `<br>`)를 수정하고, 원래의 HTML이 비교 불가능한 것으로 판명될 때만 예외를 던진다. 이러한 예외의 가장 큰 이유는 구문분석할 이유가 없는 빈 문서를 함수가 전달받은 경우다.  

## 문서를 단락별로 나누기
단락은 문서 구조의 단위로 기능하는 완전한 한 가지 관념을 담아 낸 부분을 말한다.  

PlaintextCorpusReader와 같은 일부 NLTK 말뭉치 리더는 paras() 메서드를 구현한다. paras() 메서드는 이중 줄바꿈으로 구분된 텍스트 블록으로 정의된 단락을 생성한다.  

그러나 여기서 우리가 다루려고 하는 텍스트는 일반적인 의미의 텍스트가 아니므로 우리는 HTML에서 단락을 추출하는 메서드를 만들어야 한다. 다행히도 우리의 html() 메서드는 HTML 문서의 구조를 유지한다. 즉, HTML 태그를 공식적으로 정의하는 `<p>`태그를 검색해 파라미터 내에서 나타나는 내용을 격리할 수 있다.  

parse() 메서드를 정의해 각 fileid를 반복하고, 각 HTML 문서를 BeautifulSoup 생성자에 전달함으로써, lxml이라는 HTML 구문분석기를 사용해 HTML을 구문분석하도록 지정한다. 그 결과로 나온 soup는 원래 HTML 태그의 요소를 사용해 탐색할 수 있는 중첩 트리 구조다. 각 문서 soup에 대해 미리 정의된 집합의 각 태그를 반복해 해당 태그 내에서 텍스트를 산출한다. 우리는 BeautifulSoup의 decompose 메서드를 호출해 메모리를 확보하기 위해 각 파일 작업을 마쳤을 때 트리르 파괴할 수 있다.