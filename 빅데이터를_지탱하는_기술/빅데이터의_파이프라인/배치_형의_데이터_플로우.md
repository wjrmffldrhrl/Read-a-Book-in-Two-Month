# 배치 형의 데이터 플로우

## 데이터 플로우
이전부터 MapReduce를 사용한 데이터 처리에서는 MapReduce 프로그램을 워크플로의 태스크로 등록함으로써 다단계의 복잡한 데이터 처리를 할 수 있었다.  
그 후 기술적인 발전에 따라 현재는 다단계의 데이터 처리를 그대로 분산 시스템의 내부에서 실행할 수 있게 되었다. 
- 이것을 **데이터 플로우(data flow)**라 지칭한다.
- 데이터 플로우 프레임워크로는 Google Cloud Dataflow, Apache Spark, Apach Flink가 있다.

### MapReduce의 구조
1. 데이터 처리를 분산하고 싶으므로, 파일을 일정 크기로 나누어 작은 데이터인 스플릿을 만든다.
2. 나눈 데이터를 읽어 들여 그중에 포함된 단어를 카운트한다.
3. 하나하나의 처리는 독립적이므로 다수의 컴퓨터에 분산할 수 있다.
4. 분산처리의 결과는 마지막에 집계해야 한다.
  - 여러 컴퓨터가 같은 단어를 센 경우도 있으므로, 다음 단계에서는 단어별로 그 수의 합계를 구한다.


분할된 데이터를 처리하는 첫 번째 단계를 MAP, 그 결과를 모아서 집계하는 두 번째 단계를 Reduce라고 부른다.  
이런 과정을 반복하면서 목적하는 결과를 얻을 때 까지 계속해서 데이터를 변환해 나가는 구조가 MapReduce다.  

### Spark의 DAG
DAG에 의한 프로그래밍의 특징은 **지연 평가(lazy evaluation)**이다. 프로그램의 각 행은 실제로는 DAG의 데이터 구조를 조립하고 있을 뿐, 거기서 특별히 뭔가를 처리하지는 않는다.  
- 먼저 DAG를 구축하고 그 후에 명시적 혹은 암묵적으로 실행 결과를 요구함에 따라 마침내 데이터 처리가 시작된다.  
- MapReduce처럼 Map과 Reduce를 하나씩 실행하는 것이 아니라, 먼저 데이터 파이프라인 전체를 DAG로 조립하고 나서 실행에 옮김으로써 내부 스케줄러가 분산 시스템에 효과적인 실행 계획을 세워주는 것이 데이터 플로우의 장점이다.  


## 데이터 플로우와 워크플로의 조합
태스크를 정기적으로 실행하거나, 실패한 태스크를 기록하여 복구하는 것은 데이터 플로우에서 할 수 없다.
- 그러기 위해서는 워크플로 관리가 필요하다.
- 따라서, 데이터 플로우의 프로그램도 다시 워크플로의 일부로서 실행되는 하나의 태스크로 고려할 수 있다.  


### 데이터를 읽어오는 플로우
데이터 플로우로부터 읽어 들일 데이터는 성능적으로 안정된 분산 스토리지에 배치하도록 한다.
- 특히 플로우가 완성될 때까지의 개발 중에는 동일 데이터를 여러 번 읽어들여 테스트하므로 분산 스토리지에 복사된 데이터만을 이용한다.

데이터 소스에서의 읽기 속도는 아무래도 한계가 있어 데이터 플로우를 사용한다고 해도 빨라진다고 단언할 수 없다.  
- 그것보다도 오류의 발생에 대해 확실하게 대처하여 복사를 끝내는 것이 선결 과제다.

데이터의 복사가 완료하면, 텍스트 데이터의 가공이나 열 지향 스토리지로의 변환 등의 부하가 큰 처리는 데이터 플로우로서 실행할 수 있다.


### 데이터를 써서 내보내는 플로우
데이터의 집계 결과를 외부 시스템에 써서 내보내는 경우에는 완전히 반대의 관계가 성립한다.  

데이터 플로우 안에서 대량의 데이터를 외부에 전송하는 것은 피하는 것이 좋다.  
- 쓰기 작업에 오랜 시간이 걸리면, 아무리 기다려도 실행이 완료되지 않고 자원을 계속해서 소비할 수 있다.
- 최악의 경우에는 쓰기 작업에 실패하여 처음부터 데이터 처리를 재실행해야 할 수도 있다.  

데이터 플로우의 출력은 CSV 파일과 같이 취급하기 쉬운 형식으로 변환하여 분산 스토리지에 써넣는다.  
- 보관이 끝나면 데이터 플로우의 역할은 끝나고 워크플로우를 통해 외부 시스템에 데이터를 전송해야 한다.  

