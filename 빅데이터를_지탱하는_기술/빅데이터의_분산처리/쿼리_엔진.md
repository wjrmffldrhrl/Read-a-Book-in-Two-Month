# 쿼리 엔진
## 데이터 마트 구축의 파이프라인
![hive_presto](../img/hive_presto.png)
1. 처음에 분산 스토리지에 저장된 데이터를 구조화하고 열 지향 스토리지 형식으로 저장한다.
    - 이것은 다수의 텍스트 파일을 읽어 들여 가공하는 부하가 큰 처리가 되기 때문에 Hive를 이용한다.
2. 완성한 구조화 데이터를 결합, 집계하고 비정규화 테이블로 데이터 마트에 써서 보낸다.


## Hive에 의한 구조화 데이터 작성
### 예시 1
```shell
$ hive

1 hive> CREATE EXTERNAL TABLE access_log_csv(
  >     time string, request string, status int, bytes int
  > )
2 > ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
3 > STORED AS TEXTFILE LOCATION '/var/log/access_log'
4 > TBLPROPERTIES ('skip.header.line.count'='1');

OK
Time taken: 1.938 seconds
```  

1. 외부 테이블 `access_log_csv`정의
    - 외부 테이블이란, Hive의 외부에 있는 특정 파일을 참고해 마치 거기에 테이블이 존재하는 것처럼 읽어 들이기 위해 지정하는 것이다.
2. CSV 형식임을 지정
3. 경로 지정
    - 디렉터리 내의 모든 파일 읽기
4. CSV의 헤더행 스킵

해당 예시는 `access_log_csv`라는 테이블명을 참고해 데이터를 추출함으로써 텍스트 파일이 로드되고 구조화 데이터로의 변환이 이루어진다.  

### 예시 2
Hive를 비롯한 대부분의 SQL-on-Hadoop의 쿼리 엔진은 MPP 데이터베이스처럼 데이터를 내부로 가져오지 않아도 텍스트 파일을 그대로 집계할 수 있다.  

```shell
hive> SELECT status, count(*) cnt
    > FROM access_log_csv GROUP BY status LIMIT 2;
...

OK
200     1701534
302     46573
Time taken: 8.664 seconds, Fetched: 2 row(s)

```
데이터를 그 자리에서 바로 집계할 수 있는 성질은 애드 혹 데이터를 분석하기에 유용하지만, CSV파일을 그대로 집계하는 것은 비효율적이므로 열 지향 스토리지로 변환해야한다.

### 예시 3 - 열 지향 스토리지로의 변환

```shell
hive> CREATE TABLE access_log_orc STORED AS ORC AS
    > SELECT cast(time AS timestamp) time,
    >        request,
    >        status,
    >        cast(bytes AS bigint) bytes
    > FROM access_log_csv;
OK
Time taken: 15.993 seconds


hive> SELECT status, count(*) cnt
    > FROM access_log_orc GROUP BY status LIMIT 2;
...
OK
200     1701534
302     46573
Time taken: 1.567 seconds, Fetched: 2 row(s)
```
Hive의 경우, 테이블마다 스토리지 형식을 지정할 수 있다.  
ORC 형식으로의 변환에는 시간이 걸리지만, 변환 후의 테입르 집계는 매우 빨라진다.  

원래 데이터가 텍스트이든 스키마리스 데이터이든 간에 그것이 Hive가 읽을 수 있는 형식이라면 무엇이든지 쿼리를 조금 고쳐 쓰는 것만으로도 어떤 테이블이라도 만들 수 있다.  

**이것이 Hive를 이용한 데이터 구조화 프로세스다.**  

### 서브 쿼리 안에서 레코드 수 줄이기
Hive는 데이터베이스가 아닌 데이터 처리를 위한 배치 처리 구조다.  
따라서, 읽어 들이는 데이터의 양을 의식하면서 쿼리를 작성하지 않으면 생각한 만큼의 성능이 나오지 않아 고민하게 된다.  

```SQL
SELECT ...
FROM access_log a
JOIN users b ON b.id = a.user_id
WHERE b.created_at = '2017-01-01'
```
위와 같이 작성하면 모든 데이터를 읽어 들인 후에 결합하고 이후에 나오는 WHERE에 의한 검색을 하게 된다.  
이렇게 되면 대량의 중간 데이터가 생성되고, 그 대부분을 그냥 버려 낭비가 되게 된다.  

```SQL
SELECT ...
-- 처음에 시간으로 팩트 테이블을 검색한다.
FROM (
    SELECT * access_log
    WHERE time >= TIMESTAMP '2017-01-01 00:00:00'
) a
JOIN users b ON b.id = a.user_id
WHERE b.created_at = '2017-01-01'
```  
위처럼 팩트 테이블을 작게 하는 것이 확실하다.  

Hive가 최적화 해주는 경우도 있어서, 서브 쿼리화가 꼭 필요한 것은 아니지만, 가능한 의식하여 **초기에 팩트 테이블을 작게 하는 것**이 빅데이터의 집계에서 중요하다.  